{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm-as-kb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEo5gIDkd3LRr1rO73mOda",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMesgar/Knowledge_Based_Systems/blob/main/lm_as_kb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LMs and Knwoledge Bases** \n",
        "This notebook explains a simple solution for the Practice II of Lecture 4. In the exercise, we are asked to focus on three relation types. These relation types are \"place of birth (POB)\", \"date of birth (DOP)\", and \"place of death (POD)\". This solution is designed for the POD. However, you should be able to learn how to design a similar solution for POB and DOP as well. "
      ],
      "metadata": {
        "id": "3wXhKzBOn-rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to upload the transformers architecture because we are going to use BERT. "
      ],
      "metadata": {
        "id": "yG6tyFR-pY0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "BV90Zaf2i8Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should read the Google RE file. To do so, we upload the file from our local machine to google colab manually. \n",
        "\n",
        "Then we read the content of the file using pandas package in Python. \n",
        "To use Pandas (similar to any other package in python) we should first import it. "
      ],
      "metadata": {
        "id": "HpFs92-RpsWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4vqTJFpcF8S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's read the content of the file. "
      ],
      "metadata": {
        "id": "JEAdv0g-qJzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pod = pd.read_json('/content/sample_data/place_of_death_test.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "QNjoS6nFcKJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many facts do exist in this dataset."
      ],
      "metadata": {
        "id": "t8HRHmt9w_ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_facts = len(pod)\n",
        "print(f\"Number of POD (place of death) facts is: {num_facts}\")"
      ],
      "metadata": {
        "id": "oBga13yVw-SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at 5 top rows in the pod dataframe. The ``head()`` function does this action for us. "
      ],
      "metadata": {
        "id": "pCtl3UBZqQVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pod.head()"
      ],
      "metadata": {
        "id": "VUpvllohguPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the column names. There are two columns that important. These columns are 'sub_label','obj_label'. These columns show which person died in which city. "
      ],
      "metadata": {
        "id": "cv5-lOodqhc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pod_data_samples = pod[['sub_label','obj_label']]"
      ],
      "metadata": {
        "id": "apYh7Es7g1J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pod_data_samples.head()"
      ],
      "metadata": {
        "id": "X18tK5QPhDxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a lits of subjects, which are persons, and their corresponding objects, which are cities in which persons died. "
      ],
      "metadata": {
        "id": "LmZMs8U8q5qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = pod['sub_label'].to_list()\n",
        "reference_objects = pod['obj_label'].to_list()"
      ],
      "metadata": {
        "id": "6rxpbnD0hlXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to evaluate BERT. The idea is to give each subject to BERT and see what it returns as the city in which the person died. \n",
        "\n",
        "Let's tell the pipeline to use BERT."
      ],
      "metadata": {
        "id": "u-jPmDwHrJ9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "HKropHgblWoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any subject in the list, we define a templae ``{s} died in [MASK]``. We give it to BERT and see what token it predictes as the object. "
      ],
      "metadata": {
        "id": "xgagsPDxrilT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for s in subjects:\n",
        "  predicted_obj = unmasker(f\"{s} died in [MASK].\")[0][\"token_str\"]\n",
        "  predictions.append(predicted_obj)"
      ],
      "metadata": {
        "id": "BKM50FoZlgXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at 10 predicted labels and 10 reference objects. We can easily compare then manually. Right?"
      ],
      "metadata": {
        "id": "geZ9sEU5r77L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions[:10])\n",
        "print(reference_objects[:10])"
      ],
      "metadata": {
        "id": "0zxLu0CpmWtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although, we can manually compare a short list of predicated labels and reference labels, we need a line of code to automatically compare the lists when they contain many items.  The following function does such comparison:"
      ],
      "metadata": {
        "id": "AVV3i8HssHwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0.0\n",
        "for i in range(num_facts):\n",
        "  predicted_label = predictions[i].lower()\n",
        "  ref_label = reference_objects[i].lower()\n",
        "  if predicted_label == ref_label:\n",
        "    correct += 1\n",
        "\n",
        "p_at_1 = correct / len(predictions)\n",
        "p_at_1 = p_at_1 * 100\n",
        "print(f\"number of facts is: {num_facts}, p@1 = {p_at_1:.2f}%\")"
      ],
      "metadata": {
        "id": "XkKUSwC1lMO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}